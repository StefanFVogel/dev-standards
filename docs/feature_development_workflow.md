# ğŸ¯ Feature Development Workflow

Dieses Dokument beschreibt den verbindlichen **4-Phasen-Prozess** fÃ¼r die Entwicklung neuer Features. Jedes Feature durchlÃ¤uft die Phasen **Spezifikation â†’ Prototyp â†’ Architektur-Review â†’ Code-Review**, bevor es in den Main-Branch gemerged wird. Der Prozess stellt sicher, dass Features vollstÃ¤ndig spezifiziert, automatisiert getestet, architektonisch sauber und dokumentiert abgenommen werden.

> **Referenz:** Das Alerts-Feature wurde als erstes Feature nach diesem Verfahren entwickelt und dient als Vorlage (siehe `docs/alert_architecture_concept.md`, `docs/alert_implementation_plan.md`, `docs/alert_codereview.md`).

---

## ğŸ“‹ Phase 1: Spezifikation

**Ziel:** Fachliche und technische Anforderungen vollstÃ¤ndig dokumentieren, bevor eine Zeile Code geschrieben wird.

### Artefakte erstellen

FÃ¼r jedes Feature werden folgende Dokumente im `docs/`-Verzeichnis des Projekts erstellt:

| Artefakt | Datei | Pflicht |
|----------|-------|---------|
| Architekturkonzept | `docs/<feature>_architecture_concept.md` | Ja |
| Implementierungsplan | `docs/<feature>_implementation_plan.md` | Ja |
| Deployment-Checkliste | `docs/<feature>_deployment.md` | Ja, wenn Infrastruktur-Ã„nderungen |
| Teststrategie | `docs/<feature>_test_strategy.md` | Optional |

### Architekturkonzept (`_architecture_concept.md`)

Das Architekturkonzept beschreibt das **Was** und **Wie** auf fachlicher und technischer Ebene. Mindest-Sektionen:

| Sektion | Inhalt |
|---------|--------|
| Ãœbersicht & Ziele | Was soll das Feature leisten? Welches Problem lÃ¶st es? |
| Datenmodell | Neue Tabellen, Felder, Relationen (ER-Diagramm empfohlen) |
| Services & Klassen | Neue Module, Klassen und deren Verantwortlichkeiten |
| API-Schnittstellen | Neue Endpoints, Request/Response-Schemas |
| Security & Privacy | Authentifizierung, Autorisierung (RBAC), Datenvalidierung, PII-Schutz |
| Phasen-Roadmap | Aufteilung in Implementierungsphasen (z.B. Phase 1: GrundgerÃ¼st, Phase 2: Business-Logik) |
| AbhÃ¤ngigkeiten | Externe Services, bestehende Module, Konfiguration |

### Implementierungsplan (`_implementation_plan.md`)

Der Implementierungsplan beschreibt das **Was** auf Task-Ebene. Jeder Task ist eine konkrete, abarbeitbare Aufgabe mit Checkbox:

```markdown
## Phase 1: GrundgerÃ¼st

- [ ] Task 1.1: Datenbank-Modelle erstellen (`models/`)
- [ ] Task 1.2: Repository-Klasse implementieren (`repositories/`)
- [ ] Task 1.3: API-Router erstellen (`routers/`)

## Phase 2: Business-Logik

- [ ] Task 2.1: Service-Klasse implementieren
- [ ] Task 2.2: Unit Tests schreiben
```

### Teststrategie (`_test_strategy.md`, optional)

Falls das Feature komplexe Testszenarien erfordert, wird die Teststrategie separat dokumentiert:

*   **Unit Tests:** Welche Klassen/Methoden werden getestet?
*   **Integration Tests:** Welche Endpoints und DatenflÃ¼sse?
*   **E2E Tests:** Welche User-Journeys werden end-to-end validiert?

### Deployment-Checkliste (`_deployment.md`, pflicht bei Infrastruktur-Ã„nderungen)

Wenn das Feature neue Azure-Komponenten, Environment-Variablen, DB-Ã„nderungen, Pods oder externe AbhÃ¤ngigkeiten einfÃ¼hrt, ist eine Deployment-Checkliste Pflicht. Vorlage und Pflicht-Sektionen siehe `standards/docs/deployment_checklist.md`.

### Abnahme-Checkliste Phase 1

- [ ] Architekturkonzept vollstÃ¤ndig (alle Mindest-Sektionen vorhanden)?
- [ ] Implementierungsplan mit konkreten Tasks und Checkboxen?
- [ ] Phasen-Roadmap definiert?
- [ ] Datenmodell dokumentiert (Tabellen, Felder, Relationen)?
- [ ] API-Schnittstellen definiert (Endpoints, Schemas)?
- [ ] Security-Aspekte (Auth, RBAC, Validierung) berÃ¼cksichtigt?
- [ ] AbhÃ¤ngigkeiten und Konfiguration identifiziert?
- [ ] Deployment-Checkliste erstellt (falls Infrastruktur-Ã„nderungen)?

---

## ğŸ¤– Phase 2: Prototyp (Claude Code)

**Ziel:** Funktionierende Implementierung, validiert gegen automatische Tests.

### Vorgehen

1.  **Kontext laden:** Claude Code erhÃ¤lt die Spezifikation (Architekturkonzept + Implementierungsplan) als Kontext.
2.  **Feature-Branch erstellen:** Alle Ã„nderungen in einem dedizierten Feature-Branch (`feature/<feature-name>`).
3.  **Tasks abarbeiten:** Jeden Task aus dem Implementierungsplan der Reihe nach umsetzen und die Checkbox abhaken.
4.  **Tests schreiben:** Automatische Tests parallel zur Implementierung schreiben.
5.  **Tests bestehen lassen:** `pytest` muss grÃ¼n sein, bevor die Phase abgeschlossen wird.
6.  **E2E validieren:** Falls eine Teststrategie existiert, die definierten E2E-Szenarien durchspielen.

### Regeln fÃ¼r die Implementierung

*   Halte dich an die Coding Standards aus `implementation.md` (Naming, Typing, Async, Error Handling).
*   Beachte die Architektur-Layer: Keine Business-Logik in Routern, Repository Pattern fÃ¼r DB-Zugriffe.
*   Docstrings fÃ¼r LLM-Tools sind funktionaler Code â€” sei prÃ¤zise.
*   Keine Breaking Changes an bestehenden Tests.

### Abnahme-Checkliste Phase 2

- [ ] Alle Tasks aus dem Implementierungsplan abgehakt?
- [ ] `pytest` grÃ¼n (alle Tests bestanden)?
- [ ] Keine Breaking Changes an bestehenden Tests?
- [ ] Feature-Branch erstellt und Code committet?
- [ ] E2E-Szenarien validiert (falls Teststrategie vorhanden)?

---

## ğŸ—ï¸ Phase 3: Architektur-Review

**Ziel:** Code-QualitÃ¤t auf **GRÃœN** bringen. Statische Analyse bestÃ¤tigt, dass der Code den Architektur-Standards entspricht.

### Vorgehen

1.  **Architekten-Ampel starten:**
    ```bash
    python standards/scripts/maintain_tools.py --mode branch
    ```
2.  **Ergebnis auswerten:**

    | Ampel | Bedeutung | Aktion |
    |-------|-----------|--------|
    | ğŸŸ¢ GRÃœN | Alle Metriken im Zielbereich | Weiter zu Phase 4 |
    | ğŸŸ¡ GELB | KomplexitÃ¤t â‰¥ 10 (Radon C) | Refactoring: Funktionen aufteilen, Early Returns |
    | ğŸ”´ ROT | KomplexitÃ¤t â‰¥ 20, Toter Code, Duplikation â‰¥ 5% | Blockierend: Sofort beheben |

3.  **Bei GELB/ROT:** Refactoring nach den Goldenen Regeln aus `architect_workflow.md` durchfÃ¼hren:
    *   Toter Code sofort lÃ¶schen (Vulture).
    *   Komplexe Funktionen aufteilen (Radon CC â‰¤ 10).
    *   Duplikate in Hilfsfunktionen extrahieren (jscpd < 5%).
4.  **Iterieren:** Schritte 1â€“3 wiederholen bis die Ampel **GRÃœN** zeigt.
5.  **Tests erneut ausfÃ¼hren:** `pytest` muss weiterhin grÃ¼n sein.

> **Referenz:** Detaillierte Anleitung in `standards/docs/architect_workflow.md`.

### Abnahme-Checkliste Phase 3

- [ ] `maintain_tools.py --mode branch` zeigt **GRÃœN**?
- [ ] `pytest` weiterhin grÃ¼n nach Refactoring?
- [ ] Keine neuen KomplexitÃ¤ts-Hotspots eingefÃ¼hrt?

---

## ğŸ” Phase 4: VollstÃ¤ndiges Code-Review

**Ziel:** Systematischer Soll/Ist-Abgleich, Visualisierung der Architektur, Methoden-Review und Identifikation von Optimierungspotenzial.

### Artefakt

Das Code-Review wird als eigenstÃ¤ndiges Dokument erstellt:

**`docs/<feature>_codereview.md`**

### Pflicht-Sektionen des Code-Review-Dokuments

#### 1. Soll/Ist-Abgleich

Jeder Task aus dem Implementierungsplan wird gegen den tatsÃ¤chlichen Code verifiziert:

| Task | Soll (aus Plan) | Ist (im Code) | Status |
|------|-----------------|----------------|--------|
| 1.1 | Datenbank-Modelle in `models/` | `models/alert.py` erstellt | âœ… OK |
| 1.2 | Repository-Klasse | `repositories/alert_repository.py` | âœ… OK |
| 2.1 | Scheduler-Service | Implementierung weicht ab: ... | âš ï¸ Abweichung |

#### 2. UML-Diagramme

Mermaid-Sequenzdiagramme fÃ¼r jeden Hauptflow (pro Phase). Beispiel:

```mermaid
sequenceDiagram
    participant User
    participant Router
    participant Service
    participant Repository
    participant DB

    User->>Router: POST /alerts
    Router->>Service: create_alert(data)
    Service->>Repository: insert(alert)
    Repository->>DB: INSERT INTO alerts
    DB-->>Repository: OK
    Repository-->>Service: Alert
    Service-->>Router: AlertResponse
    Router-->>User: 201 Created
```

#### 3. Methoden-Review

Jede neue oder geÃ¤nderte Klasse/Methode wird bewertet:

| Methode | Datei:Zeile | CC | Bewertung | Anmerkung |
|---------|-------------|-----|-----------|-----------|
| `create_alert()` | `services/alert.py:45` | 3 | âœ… Gut | Klar strukturiert |
| `process_triggers()` | `services/scheduler.py:112` | 8 | ğŸŸ¡ Akzeptabel | Aufteilen erwÃ¤gen |

#### 4. Querschnitts-Findings

Kategorisierte Findings Ã¼ber den gesamten Feature-Code:

| # | Kategorie | Finding | Severity | Datei:Zeile |
|---|-----------|---------|----------|-------------|
| 1 | Sicherheit | SQL-Injection mÃ¶glich | ğŸ”´ Hoch | `repo.py:88` |
| 2 | DB-IntegritÃ¤t | Fehlende FK-Constraint | ğŸŸ¡ Mittel | `models.py:23` |
| 3 | Performance | N+1 Query in Schleife | ğŸŸ¡ Mittel | `service.py:67` |
| 4 | Observability | Fehlender Span fÃ¼r externen Call | ğŸŸ¢ Niedrig | `client.py:34` |
| 5 | Konfigurierbarkeit | Hardcoded Timeout | ğŸŸ¢ Niedrig | `scheduler.py:15` |

**Kategorien:** Sicherheit, DB-IntegritÃ¤t, Performance, Observability, Konfigurierbarkeit.

**Severity-Stufen:** ğŸ”´ Hoch (Blocker), ğŸŸ¡ Mittel (Sollte behoben werden), ğŸŸ¢ Niedrig (Nice-to-have).

#### 5. Optimierungs-Empfehlungen

Priorisiert in drei Stufen:

| PrioritÃ¤t | Beschreibung | Zeitpunkt |
|-----------|--------------|-----------|
| **P1 â€” Vor Go-Live** | Sicherheits- und IntegritÃ¤ts-Blocker, die vor dem Merge behoben werden mÃ¼ssen | Sofort |
| **P2 â€” NÃ¤chste Iteration** | Performance-Optimierungen, Refactoring-Empfehlungen | NÃ¤chster Sprint |
| **P3 â€” Langfristig** | Architektur-Verbesserungen, technische Schulden | Backlog |

### Abnahme-Checkliste Phase 4

- [ ] Soll/Ist-Abgleich fÃ¼r alle Tasks durchgefÃ¼hrt?
- [ ] Sequenzdiagramme fÃ¼r alle Hauptflows erstellt?
- [ ] Methoden-Review fÃ¼r alle neuen/geÃ¤nderten Methoden?
- [ ] Querschnitts-Findings dokumentiert und kategorisiert?
- [ ] Optimierungs-Empfehlungen priorisiert (P1/P2/P3)?
- [ ] Alle P1-Findings behoben?
- [ ] Deployment-Checkliste vollstÃ¤ndig und verifiziert (falls vorhanden)?

---

## ğŸ“Š GesamtÃ¼bersicht

### Phasen-Tabelle

| Phase | Ziel | Input | Output | Verantwortlich |
|-------|------|-------|--------|----------------|
| 1. Spezifikation | Anforderungen dokumentieren | Feature-Idee, fachliche Anforderungen | `_architecture_concept.md`, `_implementation_plan.md` | Entwickler + Product Owner |
| 2. Prototyp | Funktionierende Implementierung | Spezifikations-Dokumente | Feature-Branch mit Code + Tests | Claude Code + Entwickler |
| 3. Architektur-Review | Code-QualitÃ¤t sicherstellen | Feature-Branch | GrÃ¼ne Architekten-Ampel | Claude Code + Entwickler |
| 4. Code-Review | Systematische Abnahme | Feature-Branch + Spezifikation | `_codereview.md` | Entwickler (Review) |

### Flussdiagramm

```mermaid
flowchart TD
    A[Feature-Idee] --> B[Phase 1: Spezifikation]
    B --> B1[architecture_concept.md]
    B --> B2[implementation_plan.md]
    B --> B3[test_strategy.md]
    B1 & B2 & B3 --> C{Spezifikation\nvollstÃ¤ndig?}
    C -- Nein --> B
    C -- Ja --> D[Phase 2: Prototyp]
    D --> D1[Feature-Branch erstellen]
    D1 --> D2[Tasks implementieren]
    D2 --> D3[Tests schreiben & bestehen]
    D3 --> E{pytest grÃ¼n?}
    E -- Nein --> D2
    E -- Ja --> F[Phase 3: Architektur-Review]
    F --> F1[maintain_tools.py --mode branch]
    F1 --> G{Ampel GRÃœN?}
    G -- Nein --> F2[Refactoring]
    F2 --> F1
    G -- Ja --> H[Phase 4: Code-Review]
    H --> H1[Soll/Ist-Abgleich]
    H --> H2[UML-Diagramme]
    H --> H3[Methoden-Review]
    H --> H4[Querschnitts-Findings]
    H --> H5[Optimierungen]
    H1 & H2 & H3 & H4 & H5 --> I{P1-Findings\nbehoben?}
    I -- Nein --> J[Fixes implementieren]
    J --> F
    I -- Ja --> K[âœ… Merge in Main]
```

---

## ğŸšï¸ Umgang mit Bestands-Projekten (Legacy Migration)

FÃ¼r Projekte, die bereits existieren und nicht "auf der grÃ¼nen Wiese" gestartet wurden, gilt eine angepasste Strategie. Wir kÃ¶nnen nicht erwarten, dass der gesamte Code sofort **GRÃœN** ist.

### Das "Ratchet"-Prinzip (Die Ratsche)

Die QualitÃ¤t darf sich niemals verschlechtern, nur verbessern. Die Ratsche dreht sich nur in eine Richtung.

1.  **Baseline definieren:**
    Der aktuelle Zustand (Anzahl Warnungen, KomplexitÃ¤t) wird als akzeptierte "Baseline" betrachtet.
2.  **New Code Policy (Strikte HÃ¤rte):**
    Jede *neue* Datei oder jedes *neue* Modul muss zu 100% den Standards entsprechen (GrÃ¼ne Ampel). Keine Ausnahmen.
3.  **Boy Scout Rule (Pfadfinder-Regel):**
    Wer eine alte Datei ("Legacy") anfasst, um einen Bug zu fixen oder ein Feature zu erweitern, muss sie **besser** hinterlassen, als er sie vorgefunden hat.
    *   *Minimum:* Keine neuen VerstÃ¶ÃŸe hinzufÃ¼gen.
    *   *Ziel:* KomplexitÃ¤t um mind. 1 Punkt senken oder 1 toten Code-Block entfernen.

---

## ğŸ”® Future Stack & Roadmap

Dieser Prozess ist lebendig. Folgende Technologien und Methoden sind fÃ¼r die zukÃ¼nftige Integration evaluiert:

| Technologie | Status | Beschreibung |
|-------------|--------|--------------|
| **uv** | ğŸ“… Geplant | Ersatz fÃ¼r `pip`/`poetry`. Extrem schneller Paketmanager (Rust-basiert). Soll langfristig das Environment-Handling Ã¼bernehmen. |
| **Mutation Testing** | ğŸ§ª Evaluierung | Tools wie `mutmut`. Ã„ndert Code absichtlich, um zu prÃ¼fen, ob Tests fehlschlagen. ErhÃ¶ht das Vertrauen in "GrÃ¼ne Tests". |
| **ADRs** | ğŸ“ Evaluierung | "Architecture Decision Records". Kurze, nummerierte Dokumente fÃ¼r Architekturentscheidungen (z.B. "Warum Redis statt Memcached?"), um das `architecture_concept` schlank zu halten. |
| **Pre-Commit Hooks** | ğŸ”„ Geplant | Automatisierte AusfÃ¼hrung von `maintain_tools.py` (Fast Mode) vor jedem `git commit`. |

---

## ğŸ”— Referenzen

| Dokument | Beschreibung |
|----------|-------------|
| `standards/docs/architect_workflow.md` | Architekten-Ampel und Refactoring-Strategie |
| `standards/docs/implementation.md` | Coding Standards, Naming, Typing, Architektur-Layer |
| `standards/docs/ai_guidelines.md` | AI-spezifische Coding-Regeln und Quality Gates |
| `standards/docs/deployment_checklist.md` | Deployment-Dokumentation: Vorlage und Pflicht-Sektionen |
